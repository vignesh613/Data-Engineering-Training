{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìù Key Points about Transformations in Spark\n",
        "\n",
        "## 1. Lazy Execution  \n",
        "- Spark doesn‚Äôt run transformations right away.  \n",
        "- Instead, it builds a **logical plan** (a DAG ‚Äì Directed Acyclic Graph).  \n",
        "- The computation only runs when an **action** (like `.show()` or `.count()`) is called.  \n",
        "\n",
        "---\n",
        "\n",
        "## 2. Return Type  \n",
        "- A **transformation** always returns a **new DataFrame or RDD**.  \n",
        "- It does **not modify** the existing one.  \n",
        "\n",
        "---\n",
        "\n",
        "## 3. Types of Transformations  \n",
        "\n",
        "### üîπ Narrow Transformations  \n",
        "- Each input partition contributes to **only one output partition**.  \n",
        "- Examples:  \n",
        "  - `map()`  \n",
        "  - `filter()`  \n",
        "  - `select()`  \n",
        "\n",
        "### üîπ Wide Transformations  \n",
        "- Data is **shuffled across partitions**.  \n",
        "- Examples:  \n",
        "  - `groupBy()`  \n",
        "  - `join()`  \n"
      ],
      "metadata": {
        "id": "8vZUbT_s1yG4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FQ18byu14Br"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}